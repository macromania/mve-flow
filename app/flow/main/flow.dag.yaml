$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
inputs:
  question:
    type: string
  pdf_url:
    type: string
outputs:
  answer:
    type: string
    reference: ${answer_prompt.output}
nodes:
- name: sourcing
  type: python
  source:
    type: code
    path: components/sourcing/sourcing_tool.py
  inputs:
    question: ${inputs.question}
    pdf_url: ${inputs.pdf_url}
- name: ingestion
  type: python
  source:
    type: code
    path: components/ingestion/ingestion_tool.py
  inputs:
    question: ${sourcing.output.question}
    pdf_url: ${sourcing.output.pdf_url}
- name: search
  type: python
  source:
    type: code
    path: components/search/search_tool.py
  inputs:
    question: ${ingestion.output.question}
    pdf_url: ${ingestion.output.pdf_url}
- name: preprocess
  type: python
  source:
    type: code
    path: components/preprocess/preprocess_tool.py
  inputs:
    question: ${search.output.question}
    pdf_url: ${search.output.pdf_url}
- name: answer_prompt
  type: llm
  source:
    type: code
    path: components/generation/answer.jinja2
  inputs:
    deployment_name: chat
    max_tokens: 256
    temperature: 0.7
    question: ${preprocess.output.question}
    context: ${preprocess.output.context}
  connection: open_ai_connection
  api: chat
